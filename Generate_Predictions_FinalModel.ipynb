{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate with train test split on train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import xgboost as xgb\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cupy as cp\n",
    "\n",
    "\n",
    "\n",
    "# Load data\n",
    "X_train = pd.read_csv('X_train_preprocessed.csv', sep=',', index_col='row_index')\n",
    "y_train = pd.read_csv('y_train_preprocessed.csv', sep=',', index_col='row_index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset\n",
    "X_train_subset, X_test, y_train_subset, y_test = train_test_split(X_train, y_train, test_size=0.05, random_state=0)\n",
    "X_train_subset, X_val, y_train_subset, y_val = train_test_split(X_train_subset, y_train_subset, test_size=0.03, random_state=0)\n",
    "\n",
    "# Convert data to GPU-compatible format\n",
    "dtrain = xgb.DMatrix(X_train_subset, label=y_train_subset)\n",
    "dval = xgb.DMatrix(X_val, label=y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adjal\\AppData\\Roaming\\Python\\Python311\\site-packages\\xgboost\\core.py:158: UserWarning: [23:53:06] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0c55ff5f71b100e98-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"n_estimators\", \"predictor\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "# Define initial parameters\n",
    "# Set up GPU parameters in XGBoost\n",
    "params = {\n",
    "    'objective': 'multi:softmax',  # Use 'multi:softmax' or 'multi:softprob' for multiclass problems\n",
    "    'num_class': len(np.unique(y_train)),  # Number of classes in your target\n",
    "    'tree_method': 'hist',  # GPU-accelerated histogram algorithm\n",
    "    'device' : 'cuda',\n",
    "    'predictor': 'gpu_predictor',  # Use GPU for predictions\n",
    "    'eval_metric': 'mlogloss',  # Evaluation metric for multiclass problems\n",
    "    'max_depth': 15,\n",
    "    'learning_rate': 0.13,\n",
    "    'n_estimators': 100,\n",
    "    'max_bin': 256,\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "# Cross-validation with early stopping\n",
    "cv_results = xgb.cv(\n",
    "    params=params,\n",
    "    dtrain=dtrain,\n",
    "    num_boost_round=500,\n",
    "    nfold=3,  # 5-fold cross-validation\n",
    "    early_stopping_rounds=10,\n",
    "    verbose_eval=True\n",
    ")\n",
    "\n",
    "# Get the best number of boosting rounds\n",
    "best_num_boost_round = len(cv_results['train-mlogloss-mean'])\n",
    "print(f\"Best number of boosting rounds: {best_num_boost_round}\")\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# Train the final model\n",
    "bst = xgb.train(\n",
    "    params=params,\n",
    "    dtrain=dtrain,\n",
    "    num_boost_round=12000,\n",
    "    evals=[(dtrain, 'train'), (dval, 'validation')],\n",
    "    early_stopping_rounds=10,\n",
    "    verbose_eval=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Accuracy: 0.9933\n",
      "train F1 Score: 0.9933\n",
      "Test Accuracy: 0.9200\n",
      "Test F1 Score: 0.9199\n"
     ]
    }
   ],
   "source": [
    "# train evaluation\n",
    "dtrain = xgb.DMatrix(X_train)\n",
    "train_predictions = bst.predict(dtrain)\n",
    "\n",
    "# Convert predictions and true labels back to CPU for metrics\n",
    "train_predictions = cp.asnumpy(train_predictions)\n",
    "y_train = y_train.to_numpy()\n",
    "\n",
    "# Evaluate\n",
    "accuracy = accuracy_score(y_train, train_predictions)\n",
    "f1 = f1_score(y_train, train_predictions, average='weighted')\n",
    "\n",
    "print(f\"train Accuracy: {accuracy:.4f}\")\n",
    "print(f\"train F1 Score: {f1:.4f}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Test evaluation\n",
    "dtest = xgb.DMatrix(X_test)\n",
    "test_predictions = bst.predict(dtest)\n",
    "\n",
    "# Convert predictions and true labels back to CPU for metrics\n",
    "test_predictions = cp.asnumpy(test_predictions)\n",
    "y_test = y_test.to_numpy()\n",
    "\n",
    "# Evaluate\n",
    "accuracy = accuracy_score(y_test, test_predictions)\n",
    "f1 = f1_score(y_test, test_predictions, average='weighted')\n",
    "\n",
    "print(f\"Test Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Test F1 Score: {f1:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fully train on X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import xgboost as xgb\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cupy as cp\n",
    "\n",
    "# Load data\n",
    "X_train = pd.read_csv('X_train_preprocessed.csv', sep=',', index_col='row_index')\n",
    "y_train = pd.read_csv('y_train_preprocessed.csv', sep=',', index_col='row_index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data\n",
    "X_train_subset, X_val, y_train_subset, y_val = train_test_split(X_train, y_train, test_size=0.05, random_state=0)\n",
    "\n",
    "# Convert data to GPU-compatible format\n",
    "dtrain = xgb.DMatrix(X_train_subset, label=y_train_subset)\n",
    "dval = xgb.DMatrix(X_val, label=y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adjal\\AppData\\Roaming\\Python\\Python311\\site-packages\\xgboost\\core.py:158: UserWarning: [23:53:17] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0c55ff5f71b100e98-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"n_estimators\", \"predictor\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "# Define initial parameters\n",
    "params = {\n",
    "    'objective': 'multi:softmax',  # Use 'multi:softmax' or 'multi:softprob' for multiclass problems\n",
    "    'num_class': len(np.unique(y_train)),  # Number of classes in your target\n",
    "    'tree_method': 'hist',  # GPU-accelerated histogram algorithm\n",
    "    'device' : 'cuda',\n",
    "    'predictor': 'gpu_predictor',  # Use GPU for predictions\n",
    "    'eval_metric': 'mlogloss',  # Evaluation metric for multiclass problems\n",
    "    'max_depth': 15,\n",
    "    'learning_rate': 0.13,\n",
    "    'n_estimators': 100,\n",
    "    'max_bin': 256,\n",
    "}\n",
    "\n",
    "\n",
    "# Train the final model\n",
    "bst = xgb.train(\n",
    "    params=params,\n",
    "    dtrain=dtrain,\n",
    "    num_boost_round=12000,\n",
    "    evals=[(dtrain, 'train'), (dval, 'validation')],\n",
    "    early_stopping_rounds=10,\n",
    "    verbose_eval=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = pd.read_csv('X_test_preprocessed.csv', sep=',', index_col='row_index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test evaluation\n",
    "dtest = xgb.DMatrix(X_test)\n",
    "test_predictions = bst.predict(dtest)\n",
    "\n",
    "# Convert predictions and true labels back to CPU for metrics\n",
    "test_predictions = cp.asnumpy(test_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to decode y_prediction_encoded\n",
    "\n",
    "def decode_y(df):\n",
    "    forward = {'Very Low': 0, 'Low': 1, 'Average': 2, 'High': 3, 'Very High': 4}\n",
    "    backward = {v: k for k, v in forward.items()}\n",
    "    df['piezo_groundwater_level_category'] = df['piezo_groundwater_level_category'].map(backward)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "ix = X_test.index\n",
    "\n",
    "df_pred = pd.DataFrame(test_predictions, index=ix, columns=['piezo_groundwater_level_category'])\n",
    "df_pred\n",
    "df_pred = decode_y(df_pred)\n",
    "df_pred.to_csv('predictionsXX.csv', index_label=\"row_index\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
